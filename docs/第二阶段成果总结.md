# 第二阶段成果总结（截至 2025-11-29）

> **阶段目标：** 利用 `reflect_env`，将 LLM 生成 Chisel 代码的 **Pass@1 Compile 成功率从 <5% 提升到 >80%**。

---

## Ⅰ. 任务一：构建 Chisel 合成数据引擎 ✅ 已完成

### 1.1 数据生成器
- **文件**: `data_gen/generator_V2.py`
- **功能**: 基于模板的批量数据生成，集成 `reflect_env` 无痕验证
- **多进程支持**: 并行验证显著提升生成效率

### 1.2 课程设计实现

| 课程等级 | 目标占比 | 实际实现 | 核心内容 |
|----------|----------|----------|----------|
| **Level 1** | 60% | ✅ | Wire/Reg/UInt/SInt/Bool 定义、基础 IO |
| **Level 2** | 30% | ✅ | Mux、When/ElseWhen、算术运算、逻辑运算、比较器 |
| **Level 3** | 10% | ✅ | 计数器、移位寄存器、边沿检测、简单 FSM |
| **Level 4** | 额外 | ✅ | 参数化模块、Valid 接口 |

### 1.3 数据资产
- **输出文件**: `dataset/chisel_sft_dataset_v2_*.jsonl`
- **数据格式**: `{"instruction": ..., "input": ..., "output": ...}`
- **验证策略**: 所有样本通过 Pass@1 Compile 验证

### 1.4 使用方法
```bash
conda activate chisel-llm
python data_gen/generator_V2.py 100 4  # 生成100条，4进程并行
```

---

## Ⅱ. 任务二：SFT 环境搭建 ✅ 已完成

### 2.1 模型选型
- **主力模型**: Qwen2.5-Coder-14B-Instruct ✅ 已下载
- **量化方式**: 4-bit QLoRA
- **缓存位置**: `~/.cache/huggingface/hub/`

### 2.2 环境配置
创建了**两个独立的 Conda 环境**以隔离依赖：

| 环境 | 用途 | 关键依赖 |
|------|------|---------|
| `chisel-llm` | 反射验证、数据生成 | Mill, Verilator, Python 3.10 |
| `chisel-train` | 模型训练、推理、评估 | transformers, torch, bitsandbytes |

### 2.3 训练工具
- **框架**: LLaMA-Factory (位于 `/home/silence_breaker/git/LLaMA-Factory`)
- **待配置**: 训练参数（LR=2e-4, Epochs=3, QLoRA 4-bit）

---

## Ⅲ. 任务三：闭环评估 🚧 进行中

### 3.1 评估框架 ✅ 已完成
- **测试集生成**: `eval/generate_eval_set.py`
- **模型评估器**: `eval/run_eval.py`
- **测试集**: `eval/eval_set_v2.jsonl` (37 条，100% 验证通过)

### 3.2 Baseline 评估结果 ✅ 已完成

**模型**: Qwen2.5-Coder-14B-Instruct（未微调，4bit 量化）

| 指标 | 结果 | 目标 |
|------|------|------|
| **Pass@1 Compile** | **91.9% (34/37)** | >80% |

#### 按难度级别
| 级别 | 通过率 |
|------|--------|
| L1-Basic | 12/12 (100%) ✅ |
| L2-Combinational | 14/14 (100%) ✅ |
| L3-Sequential | 6/9 (67%) ⚠️ |
| L4-Advanced | 2/2 (100%) ✅ |

#### 失败分析
3 个失败用例均因**缺少 import 语句**：

| 用例 | 问题 | 缺少的 import |
|------|------|---------------|
| shift_register ×2 | `not found: value Cat` | `chisel3.util.Cat` |
| fsm_simple ×1 | `Enum is not a value` | `chisel3.util._` |

### 3.3 待完成任务
- [ ] 使用 LLaMA-Factory 进行 SFT 微调
- [ ] 微调后重新评估，对比提升效果
- [ ] 针对 `chisel3.util` 包加强训练数据

---

## 核心交付物状态

| 交付物 | 状态 | 位置 |
|--------|------|------|
| 高质量合成数据集 | ✅ 已完成 | `dataset/chisel_sft_dataset_v2_*.jsonl` |
| 微调后的模型权重 (LoRA) | ⏳ 待完成 | - |

---

## 意外发现 🎉

**Baseline 模型已超预期！**

原计划目标是将 Pass@1 Compile 从 <5% 提升到 >80%，但 Qwen2.5-Coder-14B-Instruct **未经微调**已达到 **91.9%**。

这说明：
1. 该模型对 Chisel 已有较好的基础理解
2. SFT 微调的重点应放在**边缘情况**（如 `chisel3.util` 包的正确 import）
3. 可考虑更严格的评估标准（如功能验证）来区分能力提升
