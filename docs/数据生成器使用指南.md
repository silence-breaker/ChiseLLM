# 🛠️ Chisel 合成数据生成器使用指南（2025.11 更新）

本文档介绍 `data_gen/generator.py` 的使用姿势与 2025 年 11 月的最新进展。脚本用于构建高质量的 Chisel 合成数据集，服务于 LLM 的 SFT (Supervised Fine-Tuning)。

## 1. 简介

数据生成器是一个模板驱动 (Template-based) 的课程学习引擎，结合 **Curriculum Learning** 与 **Reflection Environment** 的自动验证能力。

生成流程会调用 `reflect_env` 完成编译与阐述检查，保证写入数据集的样本全部通过 "Pass@1 Compile" 校验。

## 2. 最新亮点

* **2025.11 更新**
  * `reflect_env.run_simulation` 全面支持 `silent` 模式，多进程日志不再污染进度条。
  * `sys.stdout.reconfigure()` 包裹在 try/except 中，兼容缺失该方法的 Python 运行时。
  * 进程池生命周期日志更加清晰，便于定位 JVM 预热阶段。

## 3. 核心特性

* **多进程加速 (Multiprocessing)**：自动检测 CPU 核心数，成倍提升生成吞吐。
* **无痕验证 (Silent Validation)**：调用 `reflect_env` 时默认静默模式，不产生多余文件。
* **课程设计 (Curriculum)**：
  * **Level 1 (60%)**：语法肌肉记忆 (Wire, Reg, Vec, Bundle)。
  * **Level 2 (30%)**：基础组合逻辑 (算术、Mux、When)。
  * **Level 3 (10%)**：简单时序逻辑 (Counter、ShiftRegister)。
* **Chisel 6.0 兼容**：统一使用 `import chisel3._`，与当前工具链保持一致。

## 4. 环境准备

1. 激活 Conda 环境：

    ```bash
    conda activate chisel-llm
    ```

2. 确认依赖已安装（常规环境已满足，如需手动安装可执行）：

    ```bash
    pip install tqdm jinja2
    ```

> 提示：在此环境中 `python` 已映射至 Python 3.10。如宿主机默认无此别名，可直接改用 `python3` 运行下述命令。

## 5. 快速开始

### 基本用法

在仓库根目录执行脚本，命令格式：

```bash
python data_gen/generator.py [目标样本数] [并发进程数]
```

#### 示例 1：生成 100 条测试数据（默认并发数）

```bash
python data_gen/generator.py 100
```

#### 示例 2：生成 10,000 条数据，使用 8 个进程

```bash
python data_gen/generator.py 10000 8
```

*建议并发数约为 CPU 物理核心数的一半，避免 JVM 争抢内存。*

## 6. 结果解读

运行脚本后，终端会输出类似日志：

```text
🚀 启动 Chisel 合成数据引擎 (Target: 100)
⚡ 启用多进程加速: 4 workers
📊 课程分布: Level 1 (60%) | Level 2 (30%) | Level 3 (10%)
⏳ 正在初始化并行工作进程 (JVM 预热可能需要几十秒，期间进度条可能不会更新，请耐心等待)...

35%|███▌      | 35/100 [00:45<01:20,  1.24s/it, attempts=42, rate=83.3%]
```

### 关键指标说明

1. **初始化阶段**：
    * 看到 `⏳ 正在初始化...` 表示子进程正在拉起 sbt/JVM。
    * 冷启动通常需要 **30-60 秒**，进度条暂时停留在 0% 属正常现象。

2. **进度条字段**：
    * `35/100`：已写入有效样本数 / 目标样本数。
    * `1.24s/it`：生成单条有效样本的平均耗时，包含编译验证。
    * `attempts=42`：累计尝试次数（含失败项）。
    * `rate=83.3%`：当前有效率 (有效样本 / 总尝试)。若长期低于 50%，需检查模板或环境。

3. **最终结果**：
    * 数据集输出到 `dataset/chisel_sft_dataset.jsonl`，每次运行会覆盖旧文件，如需保留历史版本请先备份。
    * JSONL 中每行含 `instruction`（指令）、`input`（空字符串）、`output`（Chisel 代码）。

> 实测（2025-11-22，目标 2，单 worker）：最终有效率 100%，平均单样本 15.4s，验证链稳定。

## 7. 进阶：扩展模板

若需覆盖更多模式，可按以下步骤扩展：

1. **定义模板**：在脚本顶部新增 Jinja2 模板字符串（例：`TEMPLATE_FSM`）。
2. **编写生成函数**：实现 `generate_xxx` 函数，渲染模板并提供 `instruction`。
3. **注册主循环**：在 `worker_task` 中纳入新的分支逻辑，并控制权重。

## 8. 常见问题

**Q: 为什么进度条一开始不动？**  
A: JVM 预热阶段。等待各进程完成 sbt 启动即可，后续速度会明显提升。

**Q: 为什么 CPU 占用率很高？**  
A: Scala/Chisel 编译极度吃 CPU。若出现系统卡顿，请降低第二个参数以减少并发度，例如 `python data_gen/generator.py 1000 4`。

**Q: 验证失败的样本会保存吗？**  
A: 不会。只有编译与阐述均通过的样本会写入 JSONL，可通过进度条中的 `rate` 监控实时通过率。
