#!/usr/bin/env python3
"""
åˆå¹¶æ•°æ®é›†å¹¶å¤åˆ¶åˆ° LLaMA-Factory

ç”¨æ³•:
    python data_gen/merge_and_prepare.py [supplement_file]
    
å¦‚æœä¸æŒ‡å®š supplement_fileï¼Œä¼šè‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°çš„ chisel_util_supplement_*.jsonl
"""

import sys
import os
import json
import glob
from datetime import datetime

def find_latest_supplement():
    """æŸ¥æ‰¾æœ€æ–°çš„è¡¥å……æ•°æ®é›†"""
    pattern = "dataset/chisel_util_supplement_*.jsonl"
    files = glob.glob(pattern)
    if not files:
        return None
    return max(files, key=os.path.getctime)

def main():
    # è·¯å¾„é…ç½®
    base_dataset = "dataset/chisel_sft_dataset_v2_20251124_081913.jsonl"
    llama_factory_data = "/home/silence_breaker/git/LLaMA-Factory/data/chisel_sft.jsonl"
    
    # æŸ¥æ‰¾è¡¥å……æ•°æ®é›†
    if len(sys.argv) > 1:
        supplement_file = sys.argv[1]
    else:
        supplement_file = find_latest_supplement()
    
    if not supplement_file or not os.path.exists(supplement_file):
        print(f"âŒ æ‰¾ä¸åˆ°è¡¥å……æ•°æ®é›†: {supplement_file}")
        print("è¯·å…ˆè¿è¡Œ generate_missing_samples.py")
        sys.exit(1)
    
    print("=" * 60)
    print("ğŸ“Š åˆå¹¶æ•°æ®é›†")
    print("=" * 60)
    print(f"  åŸºç¡€æ•°æ®é›†: {base_dataset}")
    print(f"  è¡¥å……æ•°æ®é›†: {supplement_file}")
    print(f"  ç›®æ ‡ä½ç½®: {llama_factory_data}")
    
    # è¯»å–åŸºç¡€æ•°æ®é›†
    print("\nğŸ“– è¯»å–åŸºç¡€æ•°æ®é›†...")
    base_samples = []
    with open(base_dataset, 'r', encoding='utf-8') as f:
        for line in f:
            base_samples.append(json.loads(line))
    print(f"  âœ… åŸºç¡€æ ·æœ¬: {len(base_samples)}")
    
    # è¯»å–è¡¥å……æ•°æ®é›†
    print("\nğŸ“– è¯»å–è¡¥å……æ•°æ®é›†...")
    supplement_samples = []
    with open(supplement_file, 'r', encoding='utf-8') as f:
        for line in f:
            supplement_samples.append(json.loads(line))
    print(f"  âœ… è¡¥å……æ ·æœ¬: {len(supplement_samples)}")
    
    # åˆå¹¶
    all_samples = base_samples + supplement_samples
    print(f"\nğŸ“¦ åˆå¹¶åæ€»æ ·æœ¬: {len(all_samples)}")
    
    # æ‰“ä¹±é¡ºåºï¼ˆå¯é€‰ï¼Œæœ‰åŠ©äºè®­ç»ƒï¼‰
    import random
    random.seed(42)
    random.shuffle(all_samples)
    print("  âœ… å·²æ‰“ä¹±é¡ºåº")
    
    # ç»Ÿè®¡ chisel3.util è¦†ç›–
    util_count = 0
    enum_count = 0
    popcount_count = 0
    for sample in all_samples:
        output = sample.get('output', '')
        if 'import chisel3.util' in output:
            util_count += 1
        if 'Enum(' in output:
            enum_count += 1
        if 'PopCount' in output:
            popcount_count += 1
    
    print(f"\nğŸ“Š chisel3.util ç»Ÿè®¡:")
    print(f"  - import chisel3.util: {util_count} ({util_count/len(all_samples)*100:.1f}%)")
    print(f"  - Enum(): {enum_count}")
    print(f"  - PopCount: {popcount_count}")
    
    # ä¿å­˜åˆ°æœ¬åœ°å¤‡ä»½
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_file = f"dataset/chisel_sft_merged_{timestamp}.jsonl"
    
    print(f"\nğŸ’¾ ä¿å­˜æœ¬åœ°å¤‡ä»½: {backup_file}")
    with open(backup_file, 'w', encoding='utf-8') as f:
        for sample in all_samples:
            f.write(json.dumps(sample, ensure_ascii=False) + '\n')
    
    # å¤åˆ¶åˆ° LLaMA-Factory
    print(f"\nğŸš€ å¤åˆ¶åˆ° LLaMA-Factory: {llama_factory_data}")
    with open(llama_factory_data, 'w', encoding='utf-8') as f:
        for sample in all_samples:
            f.write(json.dumps(sample, ensure_ascii=False) + '\n')
    
    print("\n" + "=" * 60)
    print("âœ… æ•°æ®å‡†å¤‡å®Œæˆï¼")
    print("=" * 60)
    print(f"  æ€»æ ·æœ¬æ•°: {len(all_samples)}")
    print(f"  chisel3.util è¦†ç›–ç‡: {util_count/len(all_samples)*100:.1f}%")
    print(f"\nä¸‹ä¸€æ­¥: è¿è¡Œè®­ç»ƒ")
    print(f"  cd /home/silence_breaker/git/LLaMA-Factory")
    print(f"  conda activate chisel-train")
    print(f"  bash run_chisel_sft.sh")

if __name__ == "__main__":
    main()
